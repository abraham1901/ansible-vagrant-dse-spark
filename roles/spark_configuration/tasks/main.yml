---
# file: roles/spark/tasks/main.yml

- name: create spark directory
  file: path={{ item }} state=directory
  with_items: spark.location

- name: cleanup tmp for spark distro
  shell: rm -rf /tmp/spark*

- name: cleanup target dir for spark
  shell: rm -rf {{ spark.location }}

- name: create target dir for spark
  shell: mkdir -p {{ spark.location }}

- name: upload spark disto from local host, don\'t forget to run download spark locally once before provisioning
  copy: src=spark-distro/spark-1.2.0-bin-hadoop2.4.tgz dest=/tmp owner=vagrant group=vagrant mode=0777

- name: extract spark from uploaded acrhive
  shell: chdir=/tmp tar zxvf /tmp/spark-1.2.0-bin-hadoop2.4.tgz

- name: copy extracted spark binaries to target
  shell: cp -rf /tmp/spark-1.2.0-bin-hadoop2.4/* {{ spark.location }}

- name: copy spark-env.sh
  template: src=spark-env.sh dest={{ spark.location }}/conf/spark-env.sh
